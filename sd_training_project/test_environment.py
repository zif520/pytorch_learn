#!/usr/bin/env python3
"""
ç¯å¢ƒæµ‹è¯•è„šæœ¬ - æ£€æŸ¥æ‰€æœ‰ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…
"""

import sys
import torch

def test_imports():
    """æµ‹è¯•æ‰€æœ‰å¿…è¦çš„åŒ…æ˜¯å¦èƒ½æ­£ç¡®å¯¼å…¥"""
    print("ğŸ” æµ‹è¯•åŒ…å¯¼å…¥...")
    
    try:
        import torch
        print(f"âœ… PyTorch: {torch.__version__}")
    except ImportError as e:
        print(f"âŒ PyTorch å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import torchvision
        print(f"âœ… TorchVision: {torchvision.__version__}")
    except ImportError as e:
        print(f"âŒ TorchVision å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import diffusers
        print(f"âœ… Diffusers: {diffusers.__version__}")
    except ImportError as e:
        print(f"âŒ Diffusers å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import transformers
        print(f"âœ… Transformers: {transformers.__version__}")
    except ImportError as e:
        print(f"âŒ Transformers å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import accelerate
        print(f"âœ… Accelerate: {accelerate.__version__}")
    except ImportError as e:
        print(f"âŒ Accelerate å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import datasets
        print(f"âœ… Datasets: {datasets.__version__}")
    except ImportError as e:
        print(f"âŒ Datasets å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from PIL import Image
        print("âœ… Pillow (PIL)")
    except ImportError as e:
        print(f"âŒ Pillow å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import numpy as np
        print(f"âœ… NumPy: {np.__version__}")
    except ImportError as e:
        print(f"âŒ NumPy å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import tqdm
        print(f"âœ… TQDM: {tqdm.__version__}")
    except ImportError as e:
        print(f"âŒ TQDM å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def test_device():
    """æµ‹è¯•å¯ç”¨çš„è®¡ç®—è®¾å¤‡"""
    print("\nğŸ” æµ‹è¯•è®¡ç®—è®¾å¤‡...")
    
    if torch.backends.mps.is_available():
        print("âœ… MPS (Apple Silicon) å¯ç”¨")
        device = torch.device("mps")
        try:
            # æµ‹è¯• MPS æ˜¯å¦çœŸçš„å¯ç”¨
            test_tensor = torch.randn(2, 2).to(device)
            print("âœ… MPS è®¾å¤‡æµ‹è¯•é€šè¿‡")
        except Exception as e:
            print(f"âŒ MPS è®¾å¤‡æµ‹è¯•å¤±è´¥: {e}")
            device = torch.device("cpu")
            print("âš ï¸  å›é€€åˆ° CPU")
    elif torch.cuda.is_available():
        print("âœ… CUDA å¯ç”¨")
        device = torch.device("cuda")
        print(f"GPU: {torch.cuda.get_device_name()}")
    else:
        print("âš ï¸  ä»… CPU å¯ç”¨")
        device = torch.device("cpu")
    
    return device

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½ï¼ˆä¸ä¸‹è½½ï¼Œåªæµ‹è¯•è¿æ¥ï¼‰"""
    print("\nğŸ” æµ‹è¯•æ¨¡å‹åŠ è½½...")
    
    try:
        from transformers import CLIPTokenizer
        tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-large-patch14")
        print("âœ… CLIP Tokenizer åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ CLIP Tokenizer åŠ è½½å¤±è´¥: {e}")
        return False
    
    return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Stable Diffusion è®­ç»ƒç¯å¢ƒæµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯• Python ç‰ˆæœ¬
    print(f"Python ç‰ˆæœ¬: {sys.version}")
    
    # æµ‹è¯•åŒ…å¯¼å…¥
    if not test_imports():
        print("\nâŒ åŒ…å¯¼å…¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–å®‰è£…")
        return False
    
    # æµ‹è¯•è®¾å¤‡
    device = test_device()
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    if not test_model_loading():
        print("\nâŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return False
    
    print("\n" + "=" * 50)
    print("âœ… ç¯å¢ƒæµ‹è¯•å®Œæˆï¼")
    print(f"æ¨èè®¾å¤‡: {device}")
    print("\nğŸ“ ä¸‹ä¸€æ­¥:")
    print("1. å‡†å¤‡è®­ç»ƒæ•°æ®")
    print("2. ç¼–è¾‘ data/captions.txt")
    print("3. è¿è¡Œ python train_sd.py")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 